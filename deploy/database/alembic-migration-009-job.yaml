# Alembic Migration Job - Migration 009 Only (CAB-682)
# Adds catalog cache tables
# Assumes migrations 001-008 are already applied
---
apiVersion: batch/v1
kind: Job
metadata:
  name: alembic-migration-009
  namespace: stoa-system
  labels:
    app: alembic-migration
spec:
  ttlSecondsAfterFinished: 300
  backoffLimit: 3
  template:
    spec:
      restartPolicy: Never
      containers:
        - name: migration
          image: python:3.11-slim
          command:
            - /bin/bash
            - -c
            - |
              set -e
              echo "=============================================="
              echo "CAB-682: Catalog Cache Tables Migration"
              echo "=============================================="

              echo "Installing dependencies..."
              pip install --quiet sqlalchemy psycopg2-binary alembic

              echo "Creating migration files..."
              mkdir -p /app/alembic/versions
              cd /app

              # Create alembic.ini
              cat > alembic.ini <<'EOF'
              [alembic]
              script_location = alembic
              prepend_sys_path = .
              sqlalchemy.url = driver://user:pass@localhost/dbname

              [loggers]
              keys = root,sqlalchemy,alembic

              [handlers]
              keys = console

              [formatters]
              keys = generic

              [logger_root]
              level = WARN
              handlers = console

              [logger_sqlalchemy]
              level = WARN
              handlers =
              qualname = sqlalchemy.engine

              [logger_alembic]
              level = INFO
              handlers =
              qualname = alembic

              [handler_console]
              class = StreamHandler
              args = (sys.stderr,)
              level = NOTSET
              formatter = generic

              [formatter_generic]
              format = %(levelname)-5.5s [%(name)s] %(message)s
              EOF

              # Create env.py
              cat > alembic/env.py <<'ENVPY'
              from logging.config import fileConfig
              from sqlalchemy import engine_from_config, pool
              from alembic import context
              import os

              config = context.config
              config.set_main_option("sqlalchemy.url", os.environ.get("DATABASE_URL", "").replace("+asyncpg", ""))

              if config.config_file_name is not None:
                  fileConfig(config.config_file_name)

              target_metadata = None

              def run_migrations_online():
                  connectable = engine_from_config(
                      config.get_section(config.config_ini_section, {}),
                      prefix="sqlalchemy.",
                      poolclass=pool.NullPool,
                  )
                  with connectable.connect() as connection:
                      context.configure(connection=connection, target_metadata=target_metadata)
                      with context.begin_transaction():
                          context.run_migrations()

              run_migrations_online()
              ENVPY

              # Create script.py.mako
              cat > alembic/script.py.mako <<'MAKO'
              """${message}
              Revision ID: ${up_revision}
              Revises: ${down_revision | comma,n}
              """
              from alembic import op
              import sqlalchemy as sa
              ${imports if imports else ""}

              revision = ${repr(up_revision)}
              down_revision = ${repr(down_revision)}
              branch_labels = ${repr(branch_labels)}
              depends_on = ${repr(depends_on)}

              def upgrade():
                  ${upgrades if upgrades else "pass"}

              def downgrade():
                  ${downgrades if downgrades else "pass"}
              MAKO

              # Create placeholder for migration 008 (already applied)
              cat > alembic/versions/008_placeholder.py <<'MIGRATION008'
              """Placeholder for migration 008 (already applied)
              Revision ID: 008
              Revises: 007
              """
              revision = '008'
              down_revision = '007'
              branch_labels = None
              depends_on = None

              def upgrade():
                  pass

              def downgrade():
                  pass
              MIGRATION008

              # Create migration 009
              cat > alembic/versions/009_create_catalog_cache_tables.py <<'MIGRATION009'
              """Create catalog cache tables for API and MCP tools caching (CAB-682)

              Revision ID: 009
              Revises: 008
              Create Date: 2026-01-19
              """
              from alembic import op
              import sqlalchemy as sa
              from sqlalchemy.dialects import postgresql

              revision = '009'
              down_revision = '008'
              branch_labels = None
              depends_on = None

              def upgrade():
                  # Create api_catalog table
                  op.create_table(
                      'api_catalog',
                      sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
                      sa.Column('tenant_id', sa.String(100), nullable=False),
                      sa.Column('api_id', sa.String(100), nullable=False),
                      sa.Column('api_name', sa.String(255), nullable=True),
                      sa.Column('version', sa.String(50), nullable=True),
                      sa.Column('status', sa.String(50), server_default='active', nullable=False),
                      sa.Column('category', sa.String(100), nullable=True),
                      sa.Column('tags', postgresql.JSONB, server_default='[]', nullable=False),
                      sa.Column('portal_published', sa.Boolean, server_default='false', nullable=False),
                      sa.Column('metadata', postgresql.JSONB, nullable=False),
                      sa.Column('openapi_spec', postgresql.JSONB, nullable=True),
                      sa.Column('git_path', sa.String(500), nullable=True),
                      sa.Column('git_commit_sha', sa.String(40), nullable=True),
                      sa.Column('synced_at', sa.DateTime(timezone=True), server_default=sa.func.now(), nullable=False),
                      sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True),
                      sa.UniqueConstraint('tenant_id', 'api_id', name='uq_api_catalog_tenant_api')
                  )
                  op.create_index('ix_api_catalog_tenant', 'api_catalog', ['tenant_id'])
                  op.create_index('ix_api_catalog_portal', 'api_catalog', ['portal_published'])
                  op.create_index('ix_api_catalog_status', 'api_catalog', ['status'])
                  op.create_index('ix_api_catalog_category', 'api_catalog', ['category'])

                  # Create mcp_tools_catalog table
                  op.create_table(
                      'mcp_tools_catalog',
                      sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
                      sa.Column('tenant_id', sa.String(100), nullable=False),
                      sa.Column('tool_name', sa.String(100), nullable=False),
                      sa.Column('display_name', sa.String(255), nullable=True),
                      sa.Column('description', sa.Text, nullable=True),
                      sa.Column('category', sa.String(100), nullable=True),
                      sa.Column('input_schema', postgresql.JSONB, nullable=True),
                      sa.Column('output_schema', postgresql.JSONB, nullable=True),
                      sa.Column('metadata', postgresql.JSONB, server_default='{}', nullable=False),
                      sa.Column('git_path', sa.String(500), nullable=True),
                      sa.Column('git_commit_sha', sa.String(40), nullable=True),
                      sa.Column('synced_at', sa.DateTime(timezone=True), server_default=sa.func.now(), nullable=False),
                      sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True),
                      sa.UniqueConstraint('tenant_id', 'tool_name', name='uq_mcp_tools_tenant_tool')
                  )
                  op.create_index('ix_mcp_tools_tenant', 'mcp_tools_catalog', ['tenant_id'])
                  op.create_index('ix_mcp_tools_category', 'mcp_tools_catalog', ['category'])

                  # Create catalog_sync_status table
                  op.create_table(
                      'catalog_sync_status',
                      sa.Column('id', postgresql.UUID(as_uuid=True), primary_key=True, server_default=sa.text('gen_random_uuid()')),
                      sa.Column('sync_type', sa.String(50), nullable=False),
                      sa.Column('status', sa.String(50), nullable=False),
                      sa.Column('started_at', sa.DateTime(timezone=True), server_default=sa.func.now(), nullable=False),
                      sa.Column('completed_at', sa.DateTime(timezone=True), nullable=True),
                      sa.Column('items_synced', sa.Integer, server_default='0', nullable=False),
                      sa.Column('errors', postgresql.JSONB, server_default='[]', nullable=False),
                      sa.Column('git_commit_sha', sa.String(40), nullable=True)
                  )
                  op.create_index('ix_sync_status_type', 'catalog_sync_status', ['sync_type'])
                  op.create_index('ix_sync_status_status', 'catalog_sync_status', ['status'])
                  op.create_index('ix_sync_status_started_at', 'catalog_sync_status', ['started_at'])

              def downgrade():
                  op.drop_index('ix_sync_status_started_at', table_name='catalog_sync_status')
                  op.drop_index('ix_sync_status_status', table_name='catalog_sync_status')
                  op.drop_index('ix_sync_status_type', table_name='catalog_sync_status')
                  op.drop_table('catalog_sync_status')

                  op.drop_index('ix_mcp_tools_category', table_name='mcp_tools_catalog')
                  op.drop_index('ix_mcp_tools_tenant', table_name='mcp_tools_catalog')
                  op.drop_table('mcp_tools_catalog')

                  op.drop_index('ix_api_catalog_category', table_name='api_catalog')
                  op.drop_index('ix_api_catalog_status', table_name='api_catalog')
                  op.drop_index('ix_api_catalog_portal', table_name='api_catalog')
                  op.drop_index('ix_api_catalog_tenant', table_name='api_catalog')
                  op.drop_table('api_catalog')
              MIGRATION009

              echo "Checking current migration status..."
              alembic current || echo "No current revision"

              echo "Stamping database at 008 if not already..."
              alembic stamp 008 || true

              echo "Running migration to 009..."
              alembic upgrade 009

              echo "=============================================="
              echo "Migration completed!"
              echo "=============================================="
              alembic current
          env:
            - name: DATABASE_URL
              value: "postgresql://stoa:stoa-db-password-2026@control-plane-db.stoa-system.svc.cluster.local:5432/stoa"
